 %
% File acl2018.tex
%
%% Based on the style files for ACL-2017, with some changes, which were, in turn,
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2018}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{makecell}

\hypersetup{final}

\setcitestyle{square}
\setcitestyle{numbers}

\usepackage{url}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\title{Automatic Tagging of Word Relationships Using Word Embedding}

\author{Roman Tziprun \\
  {\tt romantzr@gmail.com} \\\And
  Eli Shalom \\
  {\tt eli.shalom@gmail.com} \\}

\date{31/8/2018}

\begin{document}
\maketitle
\begin{abstract}
  A great challenge to knowledge construction, manual or automatic, is context understanding. Context can be either the domain or type of the relationship between entities. For example, "France" and "Paris" are entities of type "Country" and "City" respectively,  and they form a relationship of "Capital". By understanding that the two form a specific relationship, we can improve the efficiency of knowledge construction such as in ontology building, and also improve the performance of semantic-based tasks. In this project we propose an approach for providing textual hints to the context that two entities share.
\end{abstract}
\section{Introduction}
\subsection{Motivation}
Formal knowledge representation is becoming very useful to many semantic tasks in the domain of AI in general and of NLP in particular. For example, clustering of similar web-pages is a very popular feature among search-engines (such as Google-news), and clustering of similar products is very popular in e-commerce sites (such as Amazon-shopping). Additionally, direct semantics understanding tasks which are ontology-based earn a lot from the richness of the ontology on which they are based. This may come into effect with the broadness of entities represented by the ontology (higher recall), or by increasing the granularity of entities (higher precision), or by wider relationships representation (improved accuracy).\\
Constructing knowledge is an expensive task. Manual construction requires ontologists to process and formalize information. In Cyc for example, hundreds of person-years were invested and the estimation is that 2000 person years are required to completion. Automatic construction, at the moment, is limited in capabilities and  the successful methods yield mostly entity types and common instances of relations.
\subsection{Goal}
Our project's goal is to reduce the effort required to discover and represent relations between entities in an ontology. We assume that a process for construction already exists and that it requires research from the ontologist. For example, in a geography ontology the entities "France" and "Paris" are expected to appear. Assume very little prior knowledge, then some research is required to figure out that the two entities form some relation and that this relation is "capital-of".\\
We aim to reduce the effort required to understand the existence and details of such relations.
\subsection{High-level approach}
We rely on following assumptions:
\begin{enumerate}
\item It is easier to understand using analogies
\item Analogies can be extracted through Word2vec model
\item A wide and search-able corpus is available
\end{enumerate}
The project aims to provide an understandable context through generalization. The generalization is based on two phases. Firstly, the system receives a pair of terms and using Word2vec extracts pairs that are likely to be analogous to the original pair. A fuzzy comparison on diff vector is used to determine which pairs may form an analogy. Secondly, it searches the corpus for all the documents contains the pairs. The matching documents form a unique vocabulary from which a "pattern" arise. The "pattern" starts from a set of common terms that appear in most documents. The terms are ranked using several heuristics so the most descriptive ones appear on top.
\section{System overview}
The system we developed consists of two parts. The first component (henceforth, referred to as the pairs finder) receives the input which is two words (henceforth, referred to as the source $s$ and the target $t$) and creates a list of word pairs having a similar relation as the relation between $t$ and $s$ by constructing a bipartite graph $G$ in the following manner: 
A word embedding is used to find similar\_sources, a list of 20 words that are most similar to $s$. Let $vec(w)$ be the embedding of the word $w$ in the vector space. For each word $w$ in similar\_sources, we look for 20 words that have a similar relation to $w$ as the relation between $t$ and $s$, this will be the list similar\_targets. This is done by calculating $v = vec(w) + vec(t) - vec(s)$ and looking for the 20 closest words to v. then, from similar\_targets, the word w' which is closest to w is taken, and the edge $e=(w, w')$ is added to $G$ with $weight(e)$ being the cosine distance between them. Then, vertices with degree higher than 4 are removed from the graph to reduce ambiguity. Finally, a maximal matching is computed on the graph by removing the heaviest edges iteratively until there is no vertex with degree higher than 1. This matching constitutes the list of terms which is passed to the next component.

The second component (henceforth, referred to as the label producer) receives this list of pairs as input and produces a list of words which describe the relation between the words in every pair. Let $x$ and $x'$ be a pair of words in the list returned by the pairs finder. The label producer queries a large corpus (English Wikipedia) for the term "$x$ $x'$" and gets a set of 20 most relevant pages for this term. For every page, a list $L$ of words which appear in all sentences that contain both $x$ and $x'$ is produced. Then, a tf-idf metric is calculated on these words where the term frequency of a word $y$ is is the number of occurrences of $y$ in all sentences containing both $x$ and $x'$ across all 20 pages of the given term. In the last step, a product of all tf-idf values of the same words across the result lists $L$ of all pairs is calculated, and the results are ordered by the highest tf-idf product in descending order, which gives the label list.
\section{Highly recommended}
\subsection{Pairs finding}
This is an intermediate step towards labeling. Given \textit{germany} and \textit{berlin}, the module extracts:
\begin{tabular}{ l l }
  austria & vienna \\
  slovakia & bratislava \\
  denmark & copenhagen \\
  netherlands & amsterdam \\
  poland & warsaw \\
  france & paris \\
  russia & moscow \\
  hungary & budapest \\
  britain & london

\end{tabular}

\subsection{Relation labeling}
This is the main step that given analogies generates candidate terms to label the relation. given the list of analogies generated for \textit{germany} and \textit{berlin}, the modules yields:
\begin{enumerate}
\itemsep0em 
\item \textbf{city}
\item \textbf{capital}
\item largest
\item known
\item airport
\item one
\item located
\item centre
\item listen
\item international
\end{enumerate}
As can be seen, the first two terms are the expected ones to describe the intuitive relationship between \textit{germany} and \textit{berlin}. Since the candidates are sorted by importance, this result is satisfying.

\section{Data, methods and Language-specificity}
The system assumes that a word embedding is provided where:
\begin{enumerate}
\item Words preserve distance, meaning that words that are more similar are closer to one another in the vector space (using a metric like cosine similarity) 
than words that are less similar, where similarity can be defined by context and distributional properties. For example if two words can be 
interchangeable in most context they might be considered very similar \cite{mikolov2013linguistic}.
\item Words preserve analogies, meaning that by calculating $v = vec(x) - vec(y) + vec(z)$, we get that the word $w$ for which $vec(w)$ is 
closest to $v$ should preserve the analogy $x:y::v:z$. For example the vector closest to $v = vec("Brother") - vec("Man") + vec("Woman")$ should be 
the embedding of the word "Sister" \cite{mikolov2013linguistic}. Please see our conclusions about this assumption in section \ref{AE}.
\end{enumerate}

Such a word embedding is produced by an unsupervised learning algorithm (e.g. word2vec, GloVe, fastText) where the training set is some large corpus (e.g. Wikipedia).
The word embedding is used in the pairs finder component. For simplicity, we used an already train word embedding. Specifically the GloVe model trained 
on Wikipedia with an embedding vector space of dimension $n=50$. The label producer component also uses Wikipedia as a large corpus to generate the 
labels from. It is important to note that our system can be extended to any language simply by changing the trained word vector model to a model 
of a different language and also querying a different language Wikipedia instead of the English one, though some morphological analysis such as 
stemming might be required for other languages \cite{cotterell2015morphological}.

\section{Innovation}
Enrichment of relations is a common task and an evolving one. The vast majority of papers on the topic focus on increasing the number of instances of known relations. Therefore, these tasks are classified as "Knowledge Graph Completion" (such in ~\cite{wang2014knowledge}). Additionally, most tasks assume existing structures which can be repeated ~\cite{ferragina2012fast}, or re-instantiated ~\cite{xie2016representation}. These cases are aimed at the phase which comes after initial knowledge-design (e.g. ontology construction), and rely on a "seed".

Our key differentiating points are:
\begin{enumerate}
\item Goal is improving knowledge design
\item Pure reliance on free-text
\item Strict relation analogy extraction
\item Efficient relation description ranking
\end{enumerate}

A lot of the approaches to formal knowledge construction aim at full automation of the process ~\cite{maedche2001ontology}. Due to the complexity of the task, it is bounded to have some trade-offs with the quality of the constructed knowledge. By relying on human curating, it is more likely that we achieve representation of higher quality. This of course is beneficial only in the context were great quality is indeed required (e.g. a medical application) or in domains where the automatic methods fail.

Since the method discussed here rely manual curating, a fuzzier result is expected. Therefore, the system can create keyword based descriptions, instead of pre-structured data such as Wikipedia anchors ~\cite{wang2014knowledge}.

The key innovation point is the ability to communicate by keywords, what is the type of relation that two entities form.

\section{Comparison to existing work}

\subsection{Relation analogies extraction} \label{AE}

We will start by fully disclosing that during the writing of this report we have consulted with Dr. Omer Levy about the task and realized the method we chose is rather limited ~\cite{linzen2016issues}. Additionally, the method of extracting relation analogies through word embeddings is inferior to more recent and advanced methods ~\cite{drozd2016word}.

We will start comparison with one of the original approaches appeared in \textit{Linguistic Regularities in Continuous Space Word Representations}~\cite{mikolov2013linguistic}. The method appears in the paper relates to an evaluation of analogies, such as is "car-cars$\approx$apple-apples", where $\approx$ is a predicate indicating if the two relations are analogous. In that case, the input to the system is a triplet, $w_s,w_t,w_q$, and the goal is to find $w_a$. The method in use is $w_a = \arg \max_w \frac{w \left(w_t-w_s\right)}{\norm{w}\norm{w_t-w_s}}$. We also use a similar method, but using a threshold on the similarity to determine that some candidates may introduce noise.

While remaining in the domain of word embeddings, there are methods to improve the accuracy of evaluation. On example is \textit{3COSADD} which appeared in ~\cite{levy2014linguistic}. The advantage of this method is that it takes into consideration the pair direction, which is tends to represent better semantic relations. Yet, in our model we have not determined whether it is required due to the initial candidates generation process we used.

We realize that it is possible to extend the capturing using machine learning techniques ~\cite{drozd2016word}, yet, some of these techniques may have limitations in domains with broad relation types ~\cite{levy2015supervised}.

In order to overcome some of these limitations, we have limited the type of generalization that is represented by the analogies. We require that the initial seed will be based on entities which are "highly-related" to one of the words from the input. For example, when investigating \textit{germany-berlin}, the seed will be of words that are similar to \textit{germany}. This improves the accuracy of the model in capturing semantic/domain-specific relations. Therefore, it is more likely that relations that will arise from the process will yield more intuitive "hints" in the form of keywords. This method both generates and evaluates candidates for pair analogies.

Secondly, since the source and target candidates are generated in two small spheres (euclidean-wise), it is common to have two different sources forming the same relations with a singe target. In most cases, these relations introduce noise. We use a simple greedy method to disambiguate relations, we think it could have been possible to generalize some more robust methods ~\cite{daelemans1999introduction} for this task. In practice, our greedy approach chooses a node with degree greater than one and prunes all the weak edges. For example, the following ambiguity:

\begin{tikzpicture}[node distance=1.7cm]
  % Dialectics
  \node[draw] (germany) {germany};
  \node[draw, right of=germany] (austria) {austria};
  \node[draw, below of=germany] (berlin) {berlin};
  \node[draw, right of=berlin] (vienna) {vienna};
  
  \draw[->] (germany)  edge node[left] {0.9} (berlin);
  \draw[->] (germany) edge node[left] {0.8} (vienna);
  \draw[->] (austria) edge node[right] {0.7} (vienna);
  
\end{tikzpicture}

Is resolved as:

\begin{tikzpicture}[node distance=1.75cm]
  % Dialectics
  \node[draw] (germany) {germany};
  \node[draw, right of=germany] (austria) {austria};
  \node[draw, below of=germany] (berlin) {berlin};
  \node[draw, right of=berlin] (vienna) {vienna};
  
  \draw[->] (germany)  to (berlin);
  \draw[->] (germany) edge[gray] node {X} (vienna);
    \draw[->] (austria) to (vienna);
  
\end{tikzpicture}

Since the task is a global optimization one, we could have solved it using an LP in a similar way to some classic algorithms ~\cite{aumann1998log}. Yet, in practice ambiguities appear in very few nodes, so the side effects are very narrow and global optimization has very little advantage over simple local ones.

\subsection{Description generation}

The task can be considered as meta-data extraction such as in ~\cite{yilmazel2004metaextract}. The first vertical of difference is the target entity which is being labeled. In the classical meta-data extraction the target entity is the document itself. In this case, it makes a lot of sense to assign different weights to different sections of the document such as the title. A second vertical of difference is the fact the meta-data extraction labels a single document, while the relations labels producer uses multiple documents at once. Yet, both systems, take into account relative frequency of terms as the main criteria for ranking.

A second and more relevant task is the keywords extraction task. In general, this task goal is to yield several terms for a document (given a large corpus during model preparation) that represent key concepts from the documents. Most of these tasks use a specific method, such as n-gram count in ~\cite{cohen1995highlights}, statistical approach in ~\cite{luhn1957statistical}, co-occurrences in ~\cite{matsuo2004keyword}, PAT-tree based in ~\cite{chien1997pat}, or a combination of some methods like in ~\cite{zhang2008automatic}. The task being performed by our labels producer requires a step which is not inherent to any of the other methods which is identifying commonalities. Therefore, a prior step is intersecting the vocabulary induced by each document, with some smoothing, yields a seed of "classes". The most important class is the one of words that appear in most documents. This shrinks the number of candidates significantly. Yet, the labels producer might be improved by extending the variety of heuristics.

\section{Evaluation}
Evaluating the quality of the derived word relationship is a hard task since natural language word relationships are fuzzy by their nature and deciding if a given result is good or poor is a challenging task to automate. Because of this and the fact that the solution we provide has application in the field of ontology creation in mind (a task which is done in a supervised manner by the ontologist), we decided to implement a manual evaluation of the result of our process.
The evaluation was done in the following manner: We've chosen 50 word pairs. For each word pair, we've provided a word or a list of words which captures the relationship between the words in the pair. For example, for the pair (germany, berlin), we've provided the word "capital". Then, we ran our process on the pair and received a label list as a result. We gave the result a score of 0, 1 or 2, where:

\begin{enumerate}
\item[0] means the result is poor since it does not contain a word or a synonym of a word which we predicted, and it is impossible to understand the relationship between the words based on the result labels.
\item[1] means the result is neither very bad nor very good, which means it might contain a word similar to a word we predicted, but it's still hard to understand the relationship between the words from this result.
\item[2] means the result is good, which means it contains all or most of the words we predicted or their synonyms, and it's easy to understand the relationship between the words from this result.
\end{enumerate}

In our evaluation (detailed in the appendix), most word pairs either got the score 0 or 2 and only three pairs that we were not sure about were scored as 1.
Next, we summed the scores across all 50 pairs and got the score 57. We believe that this score shows that our method has a lot of potential since more than half of all pairs were labeled correctly by our standards. We also believe that additional work can be done to improve the results significantly, especially by using a domain specific word embedding as we mentioned before.

\section{Challenges and what was learned by this project}

Some of the more difficult aspects of our work were parts which involved tuning by trial and error. We tuned a lot of our system's parameters by hand until we received satisfactory results with our evaluation set. The parameters that were tuned include:
\begin{enumerate}
\item Similarity threshold: A threshold which is used to filter out words which are not similar enough to the source word when looking for similar sources.
\item Optimal graph degree in the pairs finder. This parameter is used to create a subgraph of the word relations with degree not higher than this value to reduce relational ambiguity.
\item Distance threshold: A threshold which is used to determine if a source is similar enough to the target that was chosen for it. This threshold improved the results by filtering out word pairs which are not very related. We reached the conclusion that we need to incorporate this threshold in our system after we observed that having less pairs but higher accuracy yields better results than having more pairs but lower accuracy.
For example: Providing the pair (australia, canberra) as input to the pairs finder yields the pairs (asian, tokyo), (world, athens), (india, delhi), (britain, ankara), (ireland, dublin), (scotland, christchurch), (england, aberdeen), (united, washington), (canada, ottawa), (uk, overground), (australia, canberra), (zimbabwe, harare), (sydney, melbourne). After introducing the distance threshold, the pairs (asian, tokyo), (united, washington), (uk, overground) and (sydney, melbourne) were eliminated, where 3 out of 4 of these pairs are undesired in this context.

\item Distance metrics: The understanding of when to use euclidean similarity and when to cosine similarity was challenging. It appears to be that the similarity to words vectors was not highly affected by the metric, this is mostly attributed to the high dimensionality of the space \cite{qian2004similarity}. Yet, the euclidean metric yielded results which were a little better than the cosine results.

While the results for words were comparable, for the difference vectors the results were different. After several evaluations we concluded that the cosine metric is much better for determining similarity between difference vectors. Eventually, we combined the two metrics.

\item The decision of how to combine results in the label producer. The label producer produces a list of labels for every word pair that the pair finder yields. In order to eliminate the less important labels, we used a tf-idf metric for each label, but we've struggled with how to combine the scores of all labels between all pairs. Eventually we reached the conclusion that multiplying these scores gives a good result by trial and error, which makes sense since the product will be higher when the label is more significant (higher tf-idf value) and is repeated across multiple pairs (product over a larger number of elements).
\end{enumerate}


We feel that what negatively impacted our results the most were word ambiguities since a single word has only one embedding even if it has multiple meanings \cite{shi2017jointly}. 
If we had more time, the next thing that we would have done is trained a word embedding of our own on some specific topic like music, science, history, etc. Such a word embedding can be produced on a topical corpus (e.g. Wikipedia articles related to a specific category) and can mitigate issues caused by such ambiguities.

Additionally, the restriction on pairs of unigrams only causes a significant limitation. Firstly, it increases the intensity of the ambiguities. Secondly, it introduces a lot of noise due to the partial text match happening in the labels producer. A better solution would have been to learn phrases automatically, as in \cite{mikolov2013distributed} and train a model on the processed corpus.

\section{Collaboration}

The work on the project was distributed evenly between the members. The research, the requirements definition, and the evaluation was done jointly. The coding was divided by components, where Eli was in charge of the pairs finder and Roman was in charge of the label producer.

The code is hosted in a gibhub reposity: https://github.com/elishalom/auto-word-relation-tagging/

% include your own bib file like this:
%\bibliographystyle{acl}
%\bibliographystyle{numbers}
%\bibliography{acl2018}
\bibliography{acl2018}

\bibliographystyle{acl_natbib}

\appendix
\clearpage
\onecolumn
\setcounter{secnumdepth}{0}
\section*{\centering Appendix}
\begin{longtable}[c]{|l|l|p{5cm}|l|}
\hline
\textbf{Word pair}        & \textbf{Expected labels} & \textbf{Actual labels} & \textbf{Score} \\
\hline \hline
\endhead
\multicolumn{4}{|c|}{Geography, history and politics} \\ \hline 
lincoln slavery  & end, liberator & end, emancipation, gradual, located, expressed, complex, included, private, history, form & 2 \\ \hline 
ferdinand sarajevo  & assassinated, murdered & assassination, franz, austria, june, city, riots, mortally, duchess, sophie, biographical & 2 \\ \hline 
herzl zionism  & founder, father & founder, political, state, unlike, jews, jewish, merely, modern, revisionist, birnbaum & 2 \\ \hline 
germany berlin  & capital & city, capital, largest, located, also, listen, known, university, one, national & 2 \\ \hline 
chile peso  & currency & value, inflation, currency, daily, country, colombian, currencies, reserves, taiwan, tender & 2 \\ \hline 
paris sorbonne  & academy, university & located, university, city, universities, latin, airport, also, one, capital, oldest & 2 \\ \hline 
france sarkozy  & president, leader & born, former, march, president, prime, minister, government, european, december, april & 2 \\ \hline 
nepal everest  & mountain, highest & mount, located, mountain, highest, language, known, number, also, mi, dormant & 2 \\ \hline 
america columbus  & explorer, discoverer & city, cities, united, states, european, crown, americans, world, century, first & 0 \\ \hline 
germany poland  & invaded, war & also, european, part, states, islands, union, ireland, sovereign, russian, state & 0 \\ \hline 
zhou china  & dynasty, longest & january, han, korean, october, born, south, actor, actress, chinese, dynasty & 2 \\ \hline 
turkey ataturk  & founder, revolutionary & november, state, president, resignation, born, name, istanbul, september, mikhail, russian & 1 \\ \hline 
italy lega  & party & independence, officially, soviet, known, also, national, central, socialist, english, ratified & 0 \\ \hline \hline 
\multicolumn{4}{|c|}{Art and sports} \\ \hline 
vivaldi violin  & composer & italian, known, originally, first, violins, lute, four, antonio, sonatas, baroque & 0 \\ \hline 
shakespeare hamlet  & playwright, play & story, also, world, william, written, later, television, films, english, may & 1 \\ \hline 
king shining  & author, writer & sequel, stephen, novel, episode, horror, video, bermuda, greece, film, based & 0 \\ \hline 
monet poppies  & painter & les, blooming, claude, painted & 2 \\ \hline 
barenboim piano  & composer, player & gil, album, brahms, orchestra, concerti, claudio, reverie, marcello, chung, showroom & 0 \\ \hline 
giselle perrot  & choreographer & ballet, jules, jean, pantomime, choreographer, creating, dancer, romantic, nineteenth, january & 2 \\ \hline 
bach organ  & composer & works, johann, music, six, keyboard, sonata, trio, use, composed, compositions & 2 \\ \hline 
david michelangelo  & sculptor, sculpted & marble, bernini, masterpiece, sculpture, statue, renaissance, imitation, plaster, refer, italian & 2 \\ \hline 
pacino godfather  & actor, star & film, sequel, directed, novel, starring, dick, one, story, american, day & 2 \\ \hline 
tarantino django  & director & american, written, book, also, motion, starring, picture, directed, original, western & 2 \\ \hline 
picasso cubism  & style, pioneer & paintings, art, symbolism, include, subject, century, early, also, impressionists, movement & 0 \\ \hline 
cleveland cavaliers  & team, basketball, nba, sport & season, basketball, franchise, national, association, team, professional, games, based, first & 2 \\ \hline 
higgins snooker  & champion, professional, player & professional, popularity, player, title, mark, game, john, hendry, trump, uk & 2 \\ \hline 
ballet nureyev  & dancer, ballerino, choreographer & performed, regarded, dancers, sergei, carlo, century, de, written, folk, paris & 2 \\ \hline 
joyce ulysses  & writer, author, novelist & produced, john, novel, james, irish, book, dublin, schema, gilbert, place & 0 \\ \hline \hline 
\multicolumn{4}{|c|}{Science, nature and technology} \\ \hline 
jupiter ganymede  & moon, satellite & one, known, surface, satellite, satellites, sun, orbits, orbital, mi, sky & 2 \\ \hline 
kepler exoplanet  & telescope & january, field, habitable, orbiting, star, also, may, confirmed, irwin, stars & 0 \\ \hline 
telephone bell  & inventor & company, american, new, united, states, networks, known, including, may, also & 0 \\ \hline 
penicillin fleming  & discovery, discoverer & alexander, first, sir, oxford, substance, september, carried, mould, infirmary, physiology & 0 \\ \hline 
einstein physics  & groudbreaking, theoretician & may, theory, mechanics, principles, common, force, set, gravity, freud, chemical & 0 \\ \hline 
algorithm bubble  & sort, sorting, order & also, known, sort, refer, order, brewing, sorting, juice, coffee, list & 2 \\ \hline 
graph dijkstra  & algorithm, path, shortest & algorithm, shortest, two, nodes, one, represent, path, machines, cities, variant & 2 \\ \hline 
newton gravity  & theory & well, university, mathematical, law, known, gauss, relativity, gravitation, force, mathematics & 0 \\ \hline 
lion buffalo  & predator, prey & black, africa, large, centre, leopards, oakland, cape, community, members, ontario & 0 \\ \hline 
heart tachycardia  & disease, symptom  & called, due, increase, lying, occur, includes, causes, standing, normal, within & 0 \\ \hline 
lung smoking  & disease, cancer & disease, risk, including, tobacco, also, heart, types, inhalation, often, therapy & 2 \\ \hline 
alcohol liver  & disease, failure & disease, hepatitis, alcoholic, fatty, cancer, chronic, intake, causes, including, dependence & 2 \\ \hline \hline 
\multicolumn{4}{|c|}{Misc} \\ \hline 
heracles zeus  & son, father & son, greek, hero, god, mythic, mythology, mortal, foster, divine, born & 2 \\ \hline 
shirt cotton  & material, fabric, made & textile, good, made, collared, pliable, lining, distinctively, flannel, gloves, woven & 1 \\ \hline 
owl strigiformes  & order & birds, kin, talons, typified, roller, nocturnal, stance, prey, adapted, upright & 0 \\ \hline 
toyota yaris  & model, make & car, model, generation, sold, manufactured, first, marketed, also, sedan, version & 2 \\ \hline
pasta italy  & food & dish, originating, sometimes, small, cantonese, alla, wanton, mee, italian, noun & 2 \\ \hline 
facebook zuckerberg  & founder, ceo & many, content, new, search, born, university, testing, marketing, site, management & 0 \\ \hline 
everest norgay  & climber & led, sinai, may, forest, national, later, united, also, hillary, edmund & 0 \\ \hline 
borscht beet  & ingredient & popular, green, sauce, also, dish, ukrainian, guitar, italy, italian, russian & 0 \\ \hline 
microsoft office  & developer, software, owner & also, since, service, chairman, windows, may, set, april, version, suite & 0 \\ \hline  
descartes rationalism  & philosopher, thinker, advocate & later, french, school, philosopher, thought, may, german, students, philosophical, gustav & 2 \\ \hline 
\end{longtable}

\end{document}